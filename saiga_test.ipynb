{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134b7d81-5bc2-4947-b76e-89e44832e9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin D:\\my_projects\\saiga_mistral_333\\venv\\Lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48acf355-a99f-4c32-9aa8-be7f89b84f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"IlyaGusev/saiga_mistral_7b\"\n",
    "DEFAULT_SYSTEM_PROMPT = \"Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\"\n",
    "\n",
    "DEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\n",
    "DEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6479ed31-b180-4a0f-ab6e-cd6bf41e0cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self,\n",
    "                 message_template=DEFAULT_MESSAGE_TEMPLATE,\n",
    "                 system_prompt=DEFAULT_SYSTEM_PROMPT,\n",
    "                 response_template=DEFAULT_RESPONSE_TEMPLATE):\n",
    "        \n",
    "        self.message_template = message_template\n",
    "        self.response_template = response_template\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    def add_user_message(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    def add_bot_message(self, message):\n",
    "        self.messages.append({\"role\": \"bot\", \"content\": message})\n",
    "\n",
    "    def get_prompt(self) -> str:\n",
    "        final_text = \"\"\n",
    "        for message in self.messages:\n",
    "            message_text = self.message_template.format(**message)\n",
    "            final_text += message_text\n",
    "        final_text += DEFAULT_RESPONSE_TEMPLATE\n",
    "        return final_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ec12563-0a28-4691-937a-bbdd636a122e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, tokenizer, prompt, generation_config):\n",
    "    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n",
    "    data = {k: v.to(model.device) for k, v in data.items()}\n",
    "    output_ids = model.generate(**data, generation_config=generation_config)[0]\n",
    "    output_ids = output_ids[len(data[\"input_ids\"][0]):]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return output.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2360928f-7fcf-461e-a28a-42c25ab01b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca6905c37b1a458d8cd7a5fe48e49d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True,\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path,\n",
    "                                             quantization_config=bnb_config,\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                             device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f98de7d-09b7-4b2c-9d09-2801ff2bfcf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model,\n",
    "                                  MODEL_NAME,\n",
    "                                  torch_dtype=torch.float16)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba8a0d78-9256-44c9-af7c-0d680b3229fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bebdb45-82d2-449a-91bc-c0d1e8115bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 1536,\n",
      "  \"no_repeat_ngram_size\": 15,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.2,\n",
      "  \"top_k\": 40,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "print(generation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eda775-8ad8-48ed-9101-6454f9511f6e",
   "metadata": {},
   "source": [
    "### generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d4ad171-6fd3-4b47-a910-00e27108805d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT PROMT: <s>system\n",
      "Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.</s><s>user\n",
      "Почему трава зеленая?</s><s>bot\n",
      "Почему трава зеленая?\n",
      "Зеленый цвет у растений обусловлен наличием в них химических веществ, известных как хлорофиллы. Хлорофиллы являются пигментами, которые позволяют растениям собирать энергию из света для фотосинтеза - процесса, благодаря которому они могут производить свою пищу из воды и углекислого газа.\n",
      "\n",
      "Хлорофиллы имеют особые структуры, которые позволяют им поглощать свет в определенном диапазоне длин волн, что создает видимый цвет растительности. Зеленый цвет является результатом поглощения световых лучей с длинами волн 430-560 нм, которые не поглощаются другими пигментами, такими как каротиноиды или антоцианы, которые придают красный и жёлтый цвет соответственно.\n",
      "\n",
      "Таким образом, зеленый цвет растений является результатом специфического поглощения световых лучей хлорофиллами, которые позволяют растениям проводить фотосинтез и получать питательные вещества из окружающей среды.\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = [\"Почему трава зеленая?\"]\n",
    "for inp in inputs:\n",
    "    conversation = Conversation()\n",
    "    conversation.add_user_message(inp)\n",
    "    prompt = conversation.get_prompt()\n",
    "    \n",
    "    print(f'CURRENT PROMT: {prompt}')\n",
    "\n",
    "    output = generate(model, tokenizer, prompt, generation_config)\n",
    "    print(inp)\n",
    "    print(output)\n",
    "    print()\n",
    "    print(\"==============================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "606492a4-49c1-4b56-b0ac-ea1c67d64584",
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_prompt = [\"\"\"\n",
    "Ты — Сайга, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им в управлении банком.\n",
    "\n",
    "Описание банка: \n",
    "внутренняя организация работы кредитного учреждения, с помощью которой структурируются и формализуются подходы и методы управления, \n",
    "определяются группы исполнителей, разрабатываются системы контроля и внутриорганизационных взаимоотношений.\n",
    "С помощью организационной структуры осуществляются все необходимые действия, направленные на достижение целей, которые ставит перед собой банк.\n",
    "В современном менеджменте существует несколько моделей организационных структур, которые используют кредитные организации.\n",
    "Механистическая структура наиболее традиционная. \n",
    "Каждое отдельное подразделение специализируются на своем круге операций. Механистические структуры бывают двух видов:\n",
    "1. Функциональные (или линейно-функциональные) подразделения создаются для решения определенных задач. При такой структуре в крупных кредитных организациях создается вертикальная иерархия департаментов, которые делятся на управления, а те в свою очередь – на отделы, отделы – на сектора, сектора – на группы и т. д. Функциональное деление чаще всего используется небольшими и средними кредитными организациями. В его основе – пооперационное разделение структур. Например, создаются валютный, кредитный, операционный отделы и т. п.\n",
    "2. Дивизионная структура, при которой деление организации ориентировано на потребителя, продукт или регион. \n",
    "В обязанности сотрудников соответствующих управлений входит полное обслуживание клиентов по всем видам оказываемых банком услуг. \n",
    "Они обязаны уметь объяснить правила предоставления услуг и дать свои рекомендации по возможным операциям.\n",
    "Чаще всего структурно сотрудники поделены на два-три управления: \n",
    "по работе с физическими лицами, обслуживанию юридических лиц, иногда создается специальное подразделение для VIP-клиентов. \n",
    "При дивизионной структуре существует разделение на фронт-офис, отвечающий за работу с клиентами, проведение операций, и бэк-офис, \n",
    "на который возложена работа по оформлению документации и другое обслуживание работы фронт-офиса.\n",
    "Органические структуры – альтернатива механистическим – ориентированы на быстрые изменения окружающей среды. \n",
    "К этой группе относятся такие структуры:\n",
    "– проектная, действует для реализации отдельно взятого проекта;\n",
    "– матричная, представляет собой совмещение традиционных механистических структур с проектным подходом к реализации целей.\n",
    "Организационная структура кредитных организаций не регулируется законодательно. Каждый  вправе выбирать собственную систему.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fdeb6e-8e89-4356-a1c4-69e700a3bd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сформируй организационную структуру банка, в формате JSON.\n",
      "{\n",
      "    \"name\": \"Банк\",\n",
      "    \"departments\": [\n",
      "        {\n",
      "            \"name\": \"Финансовый отдел\",\n",
      "            \"responsibilities\": [\"управление финансовыми ресурсами\", \"планирование и контроль расходов\"],\n",
      "            \"subdepartments\": [\n",
      "                {\n",
      "                    \"name\": \"Управление капиталом\",\n",
      "                    \"responsibilities\": [\"инвестиции\", \"финансирование\", \"стратегический анализ\"]\n",
      "                },\n",
      "                {\n",
      "                    \"name\": \"Управление бюджетом\",\n",
      "                    \"responsibilities\": [\"планирование и контроль расходов\", \"анализ экономической ситуации\", \"финансовые планы\"]\n",
      "                }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Отдел маркетинга\",\n",
      "            \"responsibilities\": [\"разработка стратегии развития\", \"проведение маркетинговых кампаний\", \"анализ рынка\"],\n",
      "            \"subdepartments\": [\n",
      "                { \"name\": \"Аналитический отдел\", \"responsibilities\": [\"анализ данных\", \"исследования рынка\", \"прогнозирование\"] },\n",
      "                { \"name\": \"Отдел PR\", \"responsibilities\": [\"разработка и реализация PR-стратегии\", \"обработка запросов СМИ\", \"публичное обращение\"] }\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"name\":\"Отдел информационных технологий\",\n",
      "            \"responsibilities\":[\"разработка и поддержка программного обеспечения\", \"техническое обслуживание\", \"безопасность информации\"],\n",
      "            \"subdepartments\":[\n",
      "                { \"name\": \"Разработчики\", \"responsibilities\": [\"разработка программного обеспечения\", \"тестирование\", \"поддержка\"] },\n",
      "                { \"name\": \"Администраторы\", \"responsibilities\": [\"техническое обслуживание\", \"управление безопасностью информации\", \"контроль защиты данных\"] }\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"management\": {\n",
      "        \"CEO\": \"Джон Смит\",\n",
      "        \"CFO\": \"Элизабет Джонсон\",\n",
      "        \"COO\": \"Майкл Уилсон\"\n",
      "    }\n",
      "}\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = ['Сформируй организационную структуру банка, в формате JSON.']\n",
    "\n",
    "for inp in inputs:\n",
    "    conversation = Conversation(system_prompt=bank_prompt)\n",
    "    conversation.add_user_message(inp)\n",
    "    prompt = conversation.get_prompt()\n",
    "    \n",
    "    output = generate(model, tokenizer, prompt, generation_config)\n",
    "    print(inp)\n",
    "    print(output)\n",
    "    print()\n",
    "    print(\"==============================\")\n",
    "    print()\n",
    "\n",
    "    conversation.add_bot_message(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9f1838c-06f0-43e0-834c-43d1e31bdfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добавь в финансовый отдел \"Управление рисками\".\n",
      "{\n",
      "    \"name\": \"Банк\"\n",
      "    \"departments\": [\n",
      "        {\n",
      "            \"department\": \"Финансовый отдел\",\n",
      "            \"subdepartments\": [\n",
      "                {\n",
      "                \"name\": \"Управление капиталом\",\n",
      "                \"responsibilities\": [\"инвестиции\", \"финансировние\", \"стратегический анализ\"]\n",
      "                }\n",
      "                {\n",
      "                \"name\": \"Управление бюджетом\",\n",
      "                \"responsibilities\": [\"планирование и контроль расход\", \"анализ экономической ситуации\", \"financial plans\"]\n",
      "                }\n",
      "                {\n",
      "                \"name\":\"Управление рисков\",\n",
      "                \"responsibilities\":[\"анализ рисков\", \"управление рисками\", \"стратегия минимизации рисков\"]\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = ['Добавь в финансовый отдел \"Управление рисками\".']\n",
    "\n",
    "for inp in inputs:\n",
    "    conversation.add_user_message(inp)\n",
    "    prompt = conversation.get_prompt()\n",
    "    \n",
    "    output = generate(model, tokenizer, prompt, generation_config)\n",
    "    print(inp)\n",
    "    print(output)\n",
    "    print()\n",
    "    print(\"==============================\")\n",
    "    print()\n",
    "\n",
    "    conversation.add_bot_message(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
